#include <curl/curl.h>
#include <iostream>
#include "yolo.hpp"
#include <thread>
#include <mutex>
#include <condition_variable>
#include <queue>
#include <atomic>
#include <sys/mman.h>
#include <signal.h>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <fcntl.h>
#include <unistd.h>
#include <sys/ioctl.h>
#include <linux/videodev2.h>
#include <opencv2/opencv.hpp> 
#include <optional>

struct SharedFrame {
    std::mutex mtx;
    std::condition_variable cv;
    std::optional<cv::Mat> frame;
    std::atomic<bool> stopFlag{false};

    std::chrono::steady_clock::time_point lastFrameTime;
    int width = 0;
    int height = 0;
} sharedFrame;

std::mutex detectionFrameMtx;
cv::Mat latestDetectionFrame;                
std::atomic<bool> newFrameReady(false);    

const std::string RTMP_LIVE = "rtmp://Your server IP:Port1/stream1";
const int FPS_LIVE = 15;
const int FPS_IMG =1 ;
const size_t QUEUE_SIZE = 1;

std::queue<cv::Mat> frameQueue;
std::mutex mtx;
std::condition_variable cvNotEmpty;
std::atomic<bool> stopFlag(false);
bool sendAlertToServer() {
    CURL* curl = curl_easy_init();
    if (!curl) {
        std::cerr << "[ERROR] åˆå§‹åŒ– curl å¤±è´¥" << std::endl;
        return false;
    }

    // æŠ¥è­¦ URL
    const std::string alertUrl = "http://Your server IP:Port2/alert";

    // è®¾ç½® POST æ•°æ®
    std::string postData = R"({"event":"person_detected","camera":"main_camera"})";

    curl_easy_setopt(curl, CURLOPT_URL, alertUrl.c_str());
    curl_easy_setopt(curl, CURLOPT_POSTFIELDS, postData.c_str());
    curl_easy_setopt(curl, CURLOPT_POSTFIELDSIZE, (long)postData.size());

    // è®¾ç½® Content-Type ä¸º JSON
    struct curl_slist* headers = nullptr;
    headers = curl_slist_append(headers, "Content-Type: application/json");
    curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);

    // æ‰§è¡Œè¯·æ±‚
    CURLcode res = curl_easy_perform(curl);
    if (res != CURLE_OK) {
        std::cerr << "[ERROR] curl_easy_perform() failed: " << curl_easy_strerror(res) << std::endl;
    } else {
        std::cout << "[INFO] å·²å‘é€æŠ¥è­¦ä¿¡æ¯åˆ°æœåŠ¡å™¨ï¼" << std::endl;
    }

    curl_easy_cleanup(curl);
    curl_slist_free_all(headers);
    return res == CURLE_OK;
}
// FFmpeg è¿›ç¨‹ç»“æ„ä½“
struct FFMpegProcess {
    FILE* pipe = nullptr;
    std::string cmd;
};

FFMpegProcess proc_live;   // å…¨å±€å˜é‡
FFMpegProcess proc_gimg;   // å…¨å±€å˜é‡

// åˆ¤æ–­ pipe æ˜¯å¦è¿˜å¯ç”¨
bool isPipeAlive(FILE* pipe) {
    return pipe && !feof(pipe) && !ferror(pipe);
}

// åˆ›å»º FFmpeg æ¨æµå­è¿›ç¨‹
FFMpegProcess startFFmpeg(const std::string& url, int fps, const std::string& tag, int width, int height) {
    char cmd[1024];
    snprintf(cmd, sizeof(cmd),
            "ffmpeg -loglevel verbose "
            "-f rawvideo -pix_fmt bgr24 -s %dx%d -r %d -i - "
            "-c:v libx264 -preset ultrafast -tune zerolatency "
            "-pix_fmt yuv420p -g 10 -b:v 512k -bf 0 "
            "-f flv %s",
            width, height, fps, url.c_str());

    std::cout << "[" << tag << "] " << cmd << std::endl;
    FILE* pipe = popen(cmd, "w");
    if (!pipe) {
        std::cerr << "æ— æ³•å¯åŠ¨ ffmpeg å­è¿›ç¨‹" << std::endl;
        exit(EXIT_FAILURE);
    }

    return {pipe, cmd};
}

// Ctrl+C å¤„ç†
void signalHandler(int s) {
   std::cerr << "\næ”¶åˆ°ç»ˆæ­¢ä¿¡å·ï¼Œå‡†å¤‡é€€å‡º...\n";
    stopFlag = true;
    // å¦‚æœæœ‰å…¶ä»–çº¿ç¨‹éœ€è¦é€šçŸ¥ï¼Œå¯ä»¥é€šè¿‡æ¡ä»¶å˜é‡æˆ–å…¶ä»–æœºåˆ¶é€šçŸ¥å®ƒä»¬
    sharedFrame.stopFlag = true; // è®¾ç½®å…±äº«å¸§çš„é€€å‡ºæ ‡å¿—
    if (proc_live.pipe) pclose(proc_live.pipe); // å…³é—­FFmpegç®¡é“
    if (proc_gimg.pipe) pclose(proc_gimg.pipe);
}

// ä½¿ç”¨ OpenCV è§£ç  MJPG æ•°æ®
cv::Mat decodeMJPEG(const unsigned char* jpegData, size_t jpegSize) {
    std::vector<uchar> data(jpegData, jpegData + jpegSize);
    cv::Mat frame = cv::imdecode(data, cv::IMREAD_COLOR); // OpenCV è‡ªåŠ¨è§£ç 
    return frame;
}
void yoloDetectionThread() {
    int frameCounter = 0;
    const int detectInterval = 60; // æ¯60å¸§æ£€æµ‹ä¸€æ¬¡

    while (!sharedFrame.stopFlag) {
        std::unique_lock<std::mutex> lock(sharedFrame.mtx);
        sharedFrame.cv.wait(lock, [&]{
            return sharedFrame.stopFlag || sharedFrame.frame.has_value();
        });

        if (sharedFrame.stopFlag)
            break;

        cv::Mat latestFrame = sharedFrame.frame.value();
        sharedFrame.frame.reset();  // æ¸…ç©ºå¸§ï¼Œé¿å…é‡å¤å¤„ç†
        lock.unlock();

        frameCounter++;
        if (frameCounter % detectInterval == 0) {
            std::cerr << "[INFO] å¼€å§‹æ‰§è¡Œ YOLO æ£€æµ‹..." << std::endl;
            std::cerr << "[DEBUG] å³å°†è°ƒç”¨ detect_yolov5_for_person()" << std::endl;
            bool personDetected = false;
            detect_yolov5_for_person(latestFrame, personDetected);
            std::cerr << "[DEBUG] detect_yolov5_for_person() è¿”å›: " << personDetected << std::endl;
            if (personDetected) {
                std::cerr << "ğŸ¤– æ£€æµ‹åˆ°äººï¼æ­£åœ¨å‘é€æŠ¥è­¦ä¿¡æ¯..." << std::endl;
                sendAlertToServer();  // å‘é€HTTPæŠ¥è­¦
            } else {
                std::cerr << "[DEBUG] æœªæ£€æµ‹åˆ°äºº" << std::endl;
            }
        }
    }

    std::cout << "[INFO] YOLO æ£€æµ‹çº¿ç¨‹å·²é€€å‡º" << std::endl;
}
int main() {
    signal(SIGINT, signalHandler);
    signal(SIGTERM, signalHandler);

    std::cout << "å¼€å§‹æ¨æµï¼›Ctrl+C é€€å‡º..." << std::endl;

    const char* dev_name = "/dev/video0";
    int fd = open(dev_name, O_RDWR);
    if (fd < 0) {
        std::cerr << "æ— æ³•æ‰“å¼€æ‘„åƒå¤´è®¾å¤‡ï¼š" << dev_name << std::endl;
        return -1;
    }

    struct v4l2_format fmt;
    memset(&fmt, 0, sizeof(fmt));
    fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    fmt.fmt.pix.width = 640;
    fmt.fmt.pix.height = 480;
    fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_MJPEG;
    fmt.fmt.pix.field = V4L2_FIELD_NONE;

    if (ioctl(fd, VIDIOC_S_FMT, &fmt) < 0) {
        std::cerr << "è®¾ç½®è§†é¢‘æ ¼å¼å¤±è´¥" << std::endl;
        close(fd);
        return -1;
    }

    int width = fmt.fmt.pix.width;
    int height = fmt.fmt.pix.height;
    sharedFrame.width = width;
    sharedFrame.height = height;
    std::cout << "æ‘„åƒå¤´åˆ†è¾¨ç‡ï¼š" << width << "x" << height << std::endl;
    
    // å¯åŠ¨ FFmpeg å­è¿›ç¨‹
    proc_live = startFFmpeg(RTMP_LIVE, FPS_LIVE, "LIVE", width, height);
    std::thread yoloThread(yoloDetectionThread);

    // è¯·æ±‚ç¼“å†²åŒº
    struct v4l2_requestbuffers req;
    memset(&req, 0, sizeof(req));
    req.count = 4;
    req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    req.memory = V4L2_MEMORY_MMAP;

    if (ioctl(fd, VIDIOC_REQBUFS, &req) < 0) {
        std::cerr << "è¯·æ±‚ç¼“å†²åŒºå¤±è´¥" << std::endl;
        close(fd);
        return -1;
    }

    void* buffers[4];
    for (unsigned int i = 0; i < req.count; ++i) {
        struct v4l2_buffer buf;
        memset(&buf, 0, sizeof(buf));
        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        buf.memory = V4L2_MEMORY_MMAP;
        buf.index = i;

        if (ioctl(fd, VIDIOC_QUERYBUF, &buf) < 0) continue;

        void* start = mmap(nullptr, buf.length, PROT_READ | PROT_WRITE, MAP_SHARED, fd, buf.m.offset);
        if (start == MAP_FAILED) continue;

        buffers[i] = start;

        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        buf.memory = V4L2_MEMORY_MMAP;
        ioctl(fd, VIDIOC_QBUF, &buf);
    }

    enum v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    ioctl(fd, VIDIOC_STREAMON, &type);
    
    int count = 0;
    while (!stopFlag) {
        struct v4l2_buffer buf;
        memset(&buf, 0, sizeof(buf));
        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        buf.memory = V4L2_MEMORY_MMAP;

        if (ioctl(fd, VIDIOC_DQBUF, &buf) < 0) {
            perror("å–å‡ºç¼“å†²åŒºå¤±è´¥");
            continue;
        }

        // ä½¿ç”¨ OpenCV è§£ç  MJPG æ•°æ®
        cv::Mat bgrFrame = decodeMJPEG((unsigned char*)buffers[buf.index], buf.bytesused);
        {
        std::lock_guard<std::mutex> lock(sharedFrame.mtx);
        sharedFrame.frame = bgrFrame.clone();  // å†™å…¥å…±äº«å¸§
        }
        sharedFrame.cv.notify_one(); 
        // æ¨é€ä¸»ç›´æ’­æµ
        if (isPipeAlive(proc_live.pipe)) {
            fwrite(bgrFrame.data, 1, bgrFrame.total() * bgrFrame.elemSize(), proc_live.pipe);
            fflush(proc_live.pipe);
        } else {
            std::cerr << "[ERROR] proc_live.pipe å·²æ–­å¼€ï¼Œåœæ­¢å†™å…¥" << std::endl;
            stopFlag = true;
        }

        ioctl(fd, VIDIOC_QBUF, &buf);
    }
if (yoloThread.joinable())
    yoloThread.join();

    std::cout << "â¹ æ­£åœ¨å…³é—­å­è¿›ç¨‹..." << std::endl;
    if (proc_live.pipe) pclose(proc_live.pipe);
    if (proc_gimg.pipe) pclose(proc_gimg.pipe);


    close(fd);
    std::cout << "ç¨‹åºæ­£å¸¸é€€å‡º" << std::endl;

    return 0;
}